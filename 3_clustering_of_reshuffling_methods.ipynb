{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75a712d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import xgi\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "from itertools import combinations\n",
    "from scipy.spatial import distance\n",
    "from multiprocess import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccf41bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from netsimile import *\n",
    "from portrait_divergence import *\n",
    "from hypergraphs_distances import *\n",
    "from hypergraphs_null_models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31ca285",
   "metadata": {},
   "source": [
    "# Reshuffling methods\n",
    "\n",
    "I create several realizations of each null model and compute the similarity matrix with all neasures (HNS, HPD, NS, PD). I also include the original hypergraph. The aim is to see if different reshuffling methods are correctly clustered by the similarity measures. \n",
    "\n",
    "Reshuffling methods: \n",
    "1) Random edge-shuffling (RS): we keep the number and sizes of hyperedges and place them randomly over the nodes.\n",
    "\n",
    "2) Degree-proportional edge-shuffling (PS): as before, but the probability for each node to be choosen is proportional to its hyperdegree (i.e. number of hyperedges it is part of) in the original hypergraph. \n",
    "\n",
    "3) Degree-preserving edge-shuffling (configuration model) (DS): we preserve the number of hyperedges at each order and the degree of every node at each order. This should only affect the community structure of the original hypergraph.\n",
    "\n",
    "Note: the reshuffling routine might leave the hypergraph disconnected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f3d965f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SocioPatterns_InVS13:  nodes=92, edges=603, connected=True\n",
      "SocioPatterns_InVS15:  nodes=217, edges=3279, connected=True\n",
      "SocioPatterns_LH10:  nodes=76, edges=1102, connected=True\n",
      "SocioPatterns_LyonSchool:  nodes=242, edges=10848, connected=True\n",
      "SocioPatterns_SFHH:  nodes=403, edges=6398, connected=True\n",
      "SocioPatterns_Thiers13:  nodes=327, edges=4795, connected=True\n",
      "Conferences_ECIR19:  nodes=172, edges=14068, connected=True\n",
      "Conferences_ECSS18:  nodes=164, edges=12614, connected=True\n",
      "Utah_elem_day2_0h-12h:  nodes=321, edges=5884, connected=True\n",
      "Utah_elem_day2_12h-24h:  nodes=314, edges=9875, connected=True\n",
      "CopNS_day2:  nodes=471, edges=11113, connected=False\n",
      "CopNS_day4:  nodes=471, edges=11060, connected=False\n",
      "APS_PRA_1992_1996:  nodes=10329, edges=5339, connected=False\n",
      "APS_PRB_1992_1996:  nodes=31818, edges=18572, connected=False\n",
      "APS_PRC_1992_1996:  nodes=7763, edges=3167, connected=False\n",
      "APS_PRD_1992_1996:  nodes=6465, edges=4135, connected=False\n",
      "APS_PRD_1997_2001:  nodes=7762, edges=5839, connected=False\n",
      "APS_PRD_2002_2006:  nodes=9710, edges=7186, connected=False\n",
      "APS_PRE_1992_1996:  nodes=8499, edges=4335, connected=False\n",
      "APS_PRL_1992_1996:  nodes=23861, edges=9614, connected=False\n",
      "Online_algebra_questions:  nodes=423, edges=980, connected=False\n",
      "Online_geometry_questions:  nodes=580, edges=888, connected=True\n",
      "Online_music_blues_reviews:  nodes=1106, edges=686, connected=False\n",
      "Congress_house_committees:  nodes=1290, edges=335, connected=True\n",
      "Congress_senate_committees:  nodes=282, edges=301, connected=True\n"
     ]
    }
   ],
   "source": [
    "# load data an create a hypergraph dictionary \n",
    "data_dir = ['SocioPatterns', 'Conferences', 'Utah', 'CopNS', 'APS', 'Online', 'Congress']\n",
    "H_dict = dict()\n",
    "labels = []\n",
    "\n",
    "for folder in data_dir:\n",
    "    \n",
    "    path = f'../data/{folder}'\n",
    "    files = sorted([f for f in listdir(path)])\n",
    "    \n",
    "    for f in files :\n",
    "        if f.startswith('.'):\n",
    "            continue\n",
    "        with open(f'{path}/{f}') as file: \n",
    "            data_ = json.load(file)\n",
    "        # remove eventual edges of lenght 1\n",
    "        data = [i for i in data_ if len(i)>1]\n",
    "        H = xgi.from_hyperedge_list(data)\n",
    "        # relabel and remove eventual multiple edges\n",
    "        H.cleanup(isolates=True, singletons=True, connected=False)\n",
    "        key = f'{folder}_{f}'.replace('.json', '').replace('aggr_15min_cliques_thr1_', '').replace(\n",
    "            '_hypergraph', '').replace('hyperedges_', '').replace('_simplices', '').replace('_aggr_5min', '')\n",
    "        H_dict[key] = H\n",
    "        labels.append(key)\n",
    "\n",
    "for l,H in H_dict.items():\n",
    "    print(f'{l}:  nodes={len(H.nodes)}, edges={len(H.edges)}, connected={xgi.is_connected(H)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7177c3c3-3bf6-4f61-8451-653a708044a6",
   "metadata": {},
   "source": [
    "## Compute similarity matrices for various datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e1990bf-a333-4fc9-b1c2-911ae5235511",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 3/3 [23:04<00:00, 461.35s/it]\n"
     ]
    }
   ],
   "source": [
    "# number of samples of each null model\n",
    "n_samp = 50  \n",
    "to_reshuff = ['SocioPatterns_LH10']\n",
    "\n",
    "for tag in to_reshuff:\n",
    "    \n",
    "    H = H_dict[tag]  \n",
    "    FVs = [feature_vec(H)]\n",
    "    HPs = [edge_portrait(H)]\n",
    "    G = xgi.to_graph(H)   \n",
    "    fvs = [graph_signature(G)]\n",
    "    nps = [portrait(G)]\n",
    "    shuff_methods = [edge_shuffled_hypergraph, dp_edge_shuffled_hypergraph, configuration_model_hypergraph]\n",
    "    \n",
    "    for F in tqdm(shuff_methods):  \n",
    "        H_null = [F(H, seed=i) for i in range(n_samp)] \n",
    "        G_null = [xgi.to_graph(h) for h in H_null]\n",
    "        # parallelize computations\n",
    "        p = Pool(processes=5)\n",
    "        FVs += p.map(feature_vec, H_null) \n",
    "        HPs += p.map(edge_portrait, H_null)\n",
    "        fvs += p.map(graph_signature, G_null)\n",
    "        nps += p.map(portrait, G_null)\n",
    "    \n",
    "    # compute distances between all pairs of hypergraphs\n",
    "    ds = distance.pdist(np.array(FVs), metric='canberra')\n",
    "    norm = len(FVs[0])\n",
    "    HNS_dists = list(ds / norm)\n",
    "    HPD_dists = [hyper_portrait_divergence(HPs[i],HPs[j]) \n",
    "                 for i,j in combinations(range(len(HPs)), 2) ]\n",
    "    \n",
    "    # compute distances between all pairs of networks\n",
    "    ds = distance.pdist(np.array(fvs), metric='canberra')\n",
    "    norm = len(fvs[0])\n",
    "    ns_dists = list(ds / norm)\n",
    "    pd_dists = [portrait_divergence(nps[i],nps[j]) \n",
    "                for i,j in combinations(range(len(nps)), 2) ]\n",
    "    \n",
    "    labels = ['original'] \n",
    "    for l in ['RS','PS','DS']:\n",
    "        labels += [f'{l}{i}' for i in range(n_samp)]\n",
    "        \n",
    "    results = (labels, HNS_dists, HPD_dists, ns_dists, pd_dists)\n",
    "        \n",
    "    # save results\n",
    "    with open(f'../results/reshuffling_HNS_HPD_NS_PD_{tag}.json', 'w') as res_file:\n",
    "        json.dump(results, res_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77664660-dbe1-4c9b-903d-881a250dcf2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
