{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "613c865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import xgi\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "from scipy.spatial import distance\n",
    "from multiprocess import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "238bd997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypergraphs_distances import *\n",
    "from hypergraphs_null_models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8e7304",
   "metadata": {},
   "source": [
    "# Projection-preserving null models\n",
    "\n",
    "The aim is to measure the h-or dissimilarity between the original hypergraph (H) and a randomized\n",
    "version of it (H_null). The randomization preserves the underlying projected networks, so that a standard\n",
    "distance between two graphs (e.g. NetSimile) would return a distance 0 between H and H_null.\n",
    "Here I choose one dataset and consider two type of projection-preserving null models. I try this approach with both measures: Hyper NetSimile (HNS) and Hyperedge Portrait Divergence (HPD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6446bb58-8506-43ed-9e89-312df240da84",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/SocioPatterns/aggr_15min_cliques_thr1_LH10.json') as file: \n",
    "            data = json.load(file)\n",
    "H = xgi.from_hyperedge_list(data)\n",
    "# relabel and remove eventual multiple edges\n",
    "H.cleanup(isolates=True, singletons=True, connected=False)\n",
    "tag = 'SocioPatterns_LH10'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237bda1b",
   "metadata": {},
   "source": [
    "## 1 - Random hyperedge projection (RHP)\n",
    "\n",
    "Starting form the original hypergraph, I choose at random a fraction $f$ of hyperedges and project them down to a clique. Then I measure the distance between the original hypergraph and the progressively projected ones, as a function of $f$. I realize 10 curves of $d(H,H_{null}(f))$ as a function of $f$, and try with both measures: Hyper NetSimile and Edge-Portrait Divergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3073752-59fe-40c5-a427-bee0a65ae290",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [19:01<00:00, 114.16s/it]\n"
     ]
    }
   ],
   "source": [
    "fv_data = feature_vec(H)   \n",
    "hp_data = edge_portrait(H)\n",
    "curves_HNS = []\n",
    "curves_HPD = []\n",
    "n_curves = 10\n",
    "f_space = np.linspace(0., 1., 30, endpoint=False)[1:]  # exclude f=0, f=1\n",
    "\n",
    "for i in tqdm(range(n_curves)):\n",
    "    # if f=0, distances are 0\n",
    "    curve_i_HNS = [0.]\n",
    "    curve_i_HPD = [0.]\n",
    "\n",
    "    Hs_null = [project_hedges(H, f, seed=i) for f in f_space]\n",
    "    # parallelize computations\n",
    "    p = Pool(processes=5)\n",
    "    FVs_null = p.map(feature_vec, Hs_null)\n",
    "    HPs_null = p.map(edge_portrait, Hs_null)\n",
    "    \n",
    "    curve_i_HNS += [ distance.canberra(fv_data, f_n) / len(fv_data) for f_n in FVs_null ]\n",
    "    curve_i_HPD += [ hyper_portrait_divergence(hp_data, hp_n) for hp_n in HPs_null ] \n",
    "    curves_HNS.append(curve_i_HNS)\n",
    "    curves_HPD.append(curve_i_HPD)\n",
    "\n",
    "# re-add f=0 to have consistent results\n",
    "f_space = np.linspace(0., 1., 30, endpoint=False)\n",
    "results = (list(f_space), curves_HNS, curves_HPD)\n",
    "    \n",
    "# save results\n",
    "with open(f\"../results/null_rhp_HNS_HPD_{tag}.json\", \"w\") as fp:\n",
    "    json.dump(results, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2d9646",
   "metadata": {},
   "source": [
    "## 2 - Random clique promotion (RCP) of the projected graph\n",
    "\n",
    "Randomization: First, I project the empirical hypergraph onto the corresponding pairwise network.\n",
    "Then, I randomly promote a fraction $f$ of cliques to hyperedges, at every order that is present in the original hypergraph. $f$ is thus the number of promoted $d$-cliques over the number of $d$-hyperedges in the original hypergraph, and I take it constant across orders.\n",
    "Note that hyperedges might overlap, because each d-clique always contain all the (d-1), (d-2), ..., (3) -cliques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7495ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 10/10 [1:22:03<00:00, 492.40s/it]\n"
     ]
    }
   ],
   "source": [
    "G = xgi.to_graph(H)\n",
    "curves_HNS = []\n",
    "curves_HPD = []\n",
    "n_curves = 10\n",
    "# number of h-edges of each size\n",
    "s_count = [H.edges.size.aslist().count(i) for i in range(3, 1+xgi.unique_edge_sizes(H)[-1])]\n",
    "f_space = np.linspace(0., 1.5, 41)[1:]\n",
    "\n",
    "for i in tqdm(range(n_curves)):\n",
    "    curve_i_HNS = [] \n",
    "    curve_i_HPD = []\n",
    "\n",
    "    Hs_null = []\n",
    "    for f in f_space:\n",
    "        ns = [int(np.round(f*j)) for j in s_count]\n",
    "        Hs_null.append( flag_hypergraph(G, ns, seed=i) )\n",
    "    # parallelize computations\n",
    "    p = Pool(processes=5)\n",
    "    FVs_null = p.map(feature_vec, Hs_null)\n",
    "    HPs_null = p.map(edge_portrait, Hs_null)\n",
    "        \n",
    "    curve_i_HNS = [ distance.canberra(fv_data, f_n) / len(fv_data) for f_n in FVs_null ]\n",
    "    curve_i_HPD = [ hyper_portrait_divergence(hp_data, hp_n) for hp_n in HPs_null ]      \n",
    "    curves_HNS.append(curve_i_HNS)\n",
    "    curves_HPD.append(curve_i_HPD)\n",
    "\n",
    "results = (list(f_space), curves_HNS, curves_HPD)\n",
    "    \n",
    "# save results\n",
    "with open(f\"../results/null_rcp_HNS_HPD_{tag}.json\", \"w\") as fp:\n",
    "    json.dump(results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589e8f02-2a50-46ae-b7ec-b92ffe976cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
